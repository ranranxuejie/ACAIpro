# è¾“å…¥åŒºåŸŸæ¨¡å— - å¤„ç†èŠå¤©è¾“å…¥å’Œç”¨æˆ·è¾“å…¥å¤„ç†
import streamlit as st
from .core import AIClient
from .utils import process_ai_content
from .file_utils import format_file_attachments

# æ¸²æŸ“è¾“å…¥åŒºåŸŸ
def render_input_area():
    """
    æ¸²æŸ“è¾“å…¥åŒºåŸŸç»„ä»¶
    """
    
    # èŠå¤©è¾“å…¥æ¡† - æ”¯æŒæ–‡ä»¶ä¸Šä¼ ï¼Œä½¿ç”¨st.chat_inputçš„accept_fileå‚æ•°
    chat_input = st.chat_input(
        placeholder="è¯¢é—®ä»»ä½•é—®é¢˜",
        key="chat_input",
        accept_file=True,  # æ”¯æŒä¸Šä¼ æ–‡ä»¶
        max_chars=None,     # æ— å­—ç¬¦é™åˆ¶
        accept_audio=True,  # æ”¯æŒä¸Šä¼ éŸ³é¢‘
    )

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    if chat_input:
        # è·å–æ–‡æœ¬å†…å®¹
        prompt = chat_input.get("text", "")
        
        # è·å–ä¸Šä¼ çš„æ–‡ä»¶
        uploaded_files = chat_input.get("files", [])
        uploaded_file = uploaded_files[0] if uploaded_files else None
        
        # æ˜¾ç¤ºä¸Šä¼ æ–‡ä»¶ä¿¡æ¯
        if uploaded_file:
            st.toast(f"å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}", icon="âœ…")
        
        # è°ƒç”¨å¤„ç†å‡½æ•°
        handle_user_input(prompt, uploaded_file)

# å¤„ç†ç”¨æˆ·è¾“å…¥
def handle_user_input(prompt, uploaded_file):
    """
    å¤„ç†ç”¨æˆ·è¾“å…¥
    
    Args:
        prompt (str): ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
        uploaded_file: ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
    """
    # æ£€æŸ¥æ˜¯å¦è¿æ¥
    if not st.session_state.bot:
        st.error("è¯·å…ˆè¿æ¥ä¼šè¯ï¼")
    else:
        # --- ç”¨æˆ·æ¶ˆæ¯å¤„ç† ---
        file_name_record = uploaded_file.name if uploaded_file else None

        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯ï¼Œå°†æ–‡ä»¶ä¿¡æ¯é›†æˆåˆ°å¯¹è¯å†…å®¹ä¸­
        with st.chat_message("user"):
            # ä½¿ç”¨file_utilsæ¨¡å—æ ¼å¼åŒ–æ–‡ä»¶é™„ä»¶
            file_html = format_file_attachments([], file_name_record, f"{file_name_record}")
            
            # å¦‚æœæœ‰æ–‡ä»¶é™„ä»¶ï¼Œä½¿ç”¨HTMLæ˜¾ç¤º
            if file_html:
                st.markdown(file_html, unsafe_allow_html=True)
                # æ·»åŠ æ¢è¡Œ
                st.markdown("\n\n")
            
            # æ˜¾ç¤ºç”¨æˆ·æ–‡æœ¬ï¼Œä½¿ç”¨st.texté¿å…markdownæ¸²æŸ“
            st.text(prompt)

        # ä¿å­˜åˆ°å†å² - æ·»åŠ tokenså±æ€§
        user_message = {
            "role": "user",
            "content": prompt,
            "file_name": file_name_record,
            "tokens": 0,  # é»˜è®¤å€¼ï¼Œå®é™…å€¼å°†ä»APIè·å–
            "files": []  # å­˜å‚¨å½“å‰æ¶ˆæ¯ç›¸å…³çš„æ–‡ä»¶
        }
        
        # å°†æ–‡ä»¶ä¿¡æ¯æ·»åŠ åˆ°å½“å‰æ¶ˆæ¯çš„fileså±æ€§ä¸­
        if file_name_record:
            file_info = {
                "name": file_name_record,
                "url": "xxx"  # å®é™…åº”ç”¨ä¸­åº”è¯¥æ˜¯æ–‡ä»¶çš„çœŸå®URL
            }
            user_message["files"].append(file_info)
            
            # åŒæ—¶æ·»åŠ åˆ°å…¨å±€useFilesåˆ—è¡¨ï¼Œé¿å…é‡å¤
            file_exists = any(file.get("name") == file_name_record for file in st.session_state.useFiles)
            if not file_exists:
                st.session_state.useFiles.append(file_info)
        
        st.session_state.messages.append(user_message)

        # --- AI æ¶ˆæ¯å¤„ç† (æµå¼) ---
        with st.chat_message("assistant"):
            # ä½¿ç”¨å•ä¸ªå ä½ç¬¦æ¥å®¹çº³æ•´ä¸ªAIå›ç­”
            response_placeholder = st.empty()
            full_response = ""
            
            # è¿­ä»£æµå¼å“åº”
            for chunk in st.session_state.bot.chat_stream(prompt, uploaded_file):
                full_response += chunk
                
                # å¤„ç†AIå›å¤ï¼ŒæŠ˜å <think>å†…å®¹
                main_content, think_content, is_thinking = process_ai_content(full_response)
                
                # æ¸…é™¤ä¹‹å‰çš„å†…å®¹
                response_placeholder.empty()
                
                # åœ¨å ä½ç¬¦ä¸­åˆ›å»ºä¸€ä¸ªå®¹å™¨ï¼Œç”¨äºæ˜¾ç¤ºå½“å‰çš„AIå›ç­”
                with response_placeholder.container():
                    # å¦‚æœæœ‰æ€è€ƒå†…å®¹ï¼Œä½¿ç”¨st.expanderæ˜¾ç¤º
                    if think_content or is_thinking:
                        with st.expander("æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹"):
                            st.markdown(f"{think_content}{'...' if is_thinking else ''}")
                    
                    # æ˜¾ç¤ºä¸»è¦å†…å®¹
                    if main_content:
                        st.markdown(main_content)

        # è·å–tokensä½¿ç”¨ä¿¡æ¯
        tokens_used = getattr(st.session_state.bot, 'last_tokens_used', 0)
        
        # ä¿å­˜ AI å›å¤åˆ°å†å² - æ·»åŠ tokenså±æ€§ï¼Œä¸åŒ…å«æ–‡ä»¶ä¿¡æ¯
        st.session_state.messages.append({
            "role": "assistant", 
            "content": full_response,
            "tokens": tokens_used  # ä½¿ç”¨å®é™…è·å–çš„tokenså€¼
        })
        
        # æ˜¾ç¤ºtokensä½¿ç”¨ä¿¡æ¯
        st.caption(f"ğŸ’¡ Use Tokens : {tokens_used}")
        
        # è‡ªåŠ¨æ»šåŠ¨åˆ°èŠå¤©åŒºåŸŸåº•éƒ¨
        # ä¿®æ”¹é€»è¾‘ï¼šç›´æ¥æ»šåŠ¨æ•´ä¸ªçª—å£åˆ°æœ€åº•éƒ¨ï¼Œå¹¶æ·»åŠ å»¶è¿Ÿä»¥ç¡®ä¿å†…å®¹æ¸²æŸ“å®Œæ¯•
        st.markdown("""
        <script>
            function scrollToBottom() {
                // è·å–æ–‡æ¡£çš„é«˜åº¦
                const scrollHeight = document.documentElement.scrollHeight || document.body.scrollHeight;
                // æ»šåŠ¨åˆ°æœ€åº•éƒ¨
                window.scrollTo({
                    top: scrollHeight,
                    behavior: "smooth"
                });
            }

            // ç«‹å³æ‰§è¡Œä¸€æ¬¡
            scrollToBottom();

            // å»¶è¿Ÿæ‰§è¡Œï¼Œç¡®ä¿ Streamlit é‡æ–°æ¸²æŸ“ DOMï¼ˆå¦‚ Markdown è§£æã€ä»£ç å—é«˜äº®ï¼‰å®Œæˆåå†æ¬¡æ»šåŠ¨
            // è®¾ç½®å¤šä¸ªæ—¶é—´ç‚¹ä»¥åº”å¯¹ä¸åŒé•¿åº¦å†…å®¹çš„æ¸²æŸ“è€—æ—¶
            setTimeout(scrollToBottom, 100);
            setTimeout(scrollToBottom, 300);
            setTimeout(scrollToBottom, 500);
        </script>
        """, unsafe_allow_html=True)
